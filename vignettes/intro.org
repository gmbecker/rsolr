#+TITLE: Introduction to rsolr

* Introduction
  The =rsolr= package provides an idiomatic (R-like) and extensible
  interface between R and Solr, a search engine and database. Like an
  onion, the interface consists of several layers, along a gradient of
  abstraction, so that simple problems are solved simply, while more
  complex problems may require some peeling and perhaps tears. The
  interface is idiomatic, syntactically but also in terms of
  /intent/. While Solr provides a search-oriented interface, we
  recognize it as a document-oriented database. While not entirely
  schemaless, its schema is extremely flexible, which makes Solr an
  effective database for prototyping and adhoc analysis. R is designed
  for manipulating data, so =rsolr= maps common R data manipulation
  verbs to the Solr database and its (limited) support for
  analytics. In other words, =rsolr= is for analysis, not search,
  which has presented some fun challenges in design. Hopefully it is
  useful --- we had not tried it until writing this document.

  We have interfaced with all of the Solr features that are relevant
  to data analysis, with the aim of implementing many of the
  fundamental data munging operations. Those operations are listed in
  the table below, along with how we have mapped those operations to
  existing and well-known functions in the base R API, with some
  important extensions. When called on =rsolr= data structures, those
  functions should behave analogously to the existing implementations
  for =data.frame=. Note that more complex operations, such as joining
  and reshaping tables, are best left to more sophisticated
  frameworks, and we encourage others to implement our extended base R
  API on top of such systems. After all, Solr is a search engine. Give
  it a break.

  | Operation      | R function  |
  |----------------+-------------|
  | Filtering      | =subset=    |
  | Transformation | =transform= |
  | Sorting        | =sort=      |
  | Aggregation    | =aggregate= |
  
* Demonstration
** The Dataset
   As part demonstration and part proof of concept, we will attempt to
   follow the introductory workflow from the =dplyr= vignette. The
   dataset describes all of the airline flights departing New York City
   in 2013. It is provided by the =nycflights13= package, so please see
   its documentation for more details.
   #+begin_src R
     library(nycflights13)
     dim(flights)
     head(flights)
   #+end_src

** Populating a Solr core
   
   The first step is getting the data into a Solr /core/, which is
   what Solr calls a database. This involves writing a schema in XML,
   installing and configuring Solr, launching the server, and
   populating the core with the actual data. Our expectation is that
   most use cases of =rsolr= will involve accessing an existing,
   centrally deployed, usually read-only Solr instance, so those are
   typically not major concerns. However, to conveniently demonstrate
   the software, we need to violate all of those assumptions.
   Luckily, we have managed to embed an example Solr installation
   within =rsolr=. We also provide a mechanism for autogenerating a
   Solr schema from a =data.frame=. This could be useful in practice
   for producing a template schema that can be tweaked and deployed in
   shared Solr installations. Taken together, the process turns out to
   not be very intimidating.

   We begin by generating the schema and starting the demo Solr
   instance. Note that this instance is really only meant for
   demonstrations. You should not abuse it like the people abused the
   poor built-in R HTTP daemon.
   #+begin_src R
     library(rsolr)
     schema <- deriveSolrSchema(flights)
     solr <- rsolr:::TestSolr(schema)
   #+end_src
   
   Next, we need to populate the core with our data. This requires a
   way to interact with the core from R. =rsolr= provides direct
   access to cores, as well as two high-level interfaces that
   represent a dataset derived from a core (rather than the core
   itself). The two interfaces each correspond to a particular shape
   of data. /SolrList/ behaves like a list, while /SolrFrame/ behaves
   like a table (data frame). /SolrList/ is useful for when the data
   are ragged, as is often the case for data stored in Solr. The Solr
   schema is so dynamic that we could trivially define a schema with a
   virtually infinite number of fields, and each document could have
   its own unique set of fields. However, since our data are tabular,
   we will use /SolrFrame/ for this exercise.
   #+begin_src R
   sr <- SolrFrame(solr$uri)
   #+end_src
   Finally, we load our data into the Solr dataset:
   #+begin_src R
   sr[] <- flights
   #+end_src
   This takes a while, since Solr has to generate all sorts of
   indices, etc.

   As /SolrFrame/ behaves much like a base R data frame, we can
   retrieve the dimensions and look at the head of the dataset:
   #+begin_src R
     dim(sr)
     head(sr)
   #+end_src
   The =head()= method returns virtually instantaneously, because the
   query is executed lazily, whenever the data are requested. One
   example of a request is when we print the object, as above.

   Comparing the output above the that of the earlier call to
   =head(flights)= reveals that the data are virtually identical. As
   Solr is just a search engine (on steroids), a significant amount of
   engineering was required to achieve that result.
   
** Restricting by row
   The simplest operation is filtering the data, i.e., restricting it
   to a subset of interest. Even a search engine should be good at
   that. Below, we use =subset= to restrict to the flights to those
   departing on January 1 (2013).
   #+begin_src R
     subset(sr, month == 1 & day == 1)
   #+end_src
   Note how the records at the bottom contain missing values. Solr
   does not provide any facilities for missing value representation,
   but we mimic it by excluding those fields from those documents.

   We can also extract ranges of data using the canonical =window()=
   function:
   #+begin_src R
     window(sr, start=1L, end=10L)
   #+end_src
   Or, as we have already seen, the more convenient:
   #+begin_src R
     head(sr, 10L)
   #+end_src
   It is unfortunately not feasible to randomly access Solr records by
   index, because numeric indexing is a foreign concept to a search
   engine. Solr does however support retrieval by a key that has a
   unique value for each document. These data lack such a key, but it
   is easy to add one and indicate as such to =deriveSolrSchema()=.

** Sorting
   To sort the data, we just call =sort()= and describe the order by
   passing a formula via the =by= argument. For example, we sort by
   year, breaking ties with month, then day:
   #+begin_src R
   sort(sr, by = ~ year + month + day)
   #+end_src

   To sort in decreasing order, just pass =decreasing=TRUE= as usual:
   #+begin_src R
   sort(sr, by = ~ arr_delay, decreasing=TRUE)
   #+end_src

** Restricting by field
   Just as we can use =subset= to restrict by row, we can also use it
   to restrict by column:
   #+begin_src R
   subset(sr, select=c(year, month, day))
   #+end_src
   The =select= argument is analogous to that of =subset.data.frame=:
   it is evaluated to set of field names to which the dataset is
   restricted. The above example is static, so it is equivalent to:
   #+begin_src R
   sr[c("year", "month", "day")]
   #+end_src
   
   But with =subset= we can also specify dynamic expressions,
   including ranges:
   #+begin_src R
   subset(sr, select=year:day)
   #+end_src
   And exclusion:
   #+begin_src R
   subset(sr, select=-(year:day))
   #+end_src
   
   Solr also has native support for globs:
   #+begin_src R
   sr[c("arr_*", "dep_*")]
   #+end_src

   While we are dealing with fields, we should mention that renaming
   is also possible:
   #+begin_src R
### FIXME: broken in current Solr CSV writer
### rename(sr, tail_num = "tailnum")
   #+end_src
   
** Transformation
   To compute new columns from existing ones, we can, as usual, call
   the =transform= function:
   #+begin_src R
     sr2 <- transform(sr,
                      gain = arr_delay - dep_delay,
                      speed = distance / air_time * 60)
     sr2[c("gain", "speed")]
   #+end_src
   
*** Advanced note
    The =transform= function essentially quotes and evaluates its
    arguments in the given frame, and then adds the results as columns
    in the return value. Direct evaluation affords more flexibility,
    such as constructing a table with only the newly computed
    columns. By default, evaluation is completely eager --- each
    referenced column is downloaded in its entirety. But we can make
    the computation lazier by calling =defer= prior to the evaluation
    via =with=:
    #+begin_src R
      with(defer(sr), data.frame(gain = head(arr_delay - dep_delay),
                                 speed = head(distance / air_time * 60)))
    #+end_src
    Note that this approach, even though it is partially deferred, is
    potentially less efficient than =transform= two reasons:
    1. It makes two requests to the database, one for each column,
    2. The two result columns are downloaded eagerly, since the result
       must be a =data.frame= (and thus practicalities required us to
       take the =head= of each promised column prior to constructing
       the data frame).
    
    We can work around the second limitation by using a more general
    form of data frame, the /DataFrame/ object from S4Vectors:
    #+begin_src R
      with(defer(sr),
           S4Vectors::DataFrame(gain = arr_delay - dep_delay,
                                speed = distance / air_time * 60))
    #+end_src
    Note that we did not need to take the =head= of the individual
    columns, since /DataFrame/ does not require the data to be stored
    in-memory as a base R vector.
    
** Summarization
   Data summarization is about reducing large, complex data to
   smaller, simpler data that we can understand.

   A common type of summarization is aggregation, which is typically
   defined as a three step process:
   1. Split the data into groups, usually by the the interaction of
      some factor set,
   2. Summarize each group to a single value,
   3. Combine the summaries.

   Solr natively supports the following types of data aggregation:
   * =mean=,
   * =min=, =max=,
   * =median=, =quantile=,
   * =var=, =sd= (/not yet working with rsolr, as Solr is evolving/),
   * =sum=,
   * count (=table=),
   * counting of unique values (for which we introduce =nunique=).
   
   The rsolr package combines and modifies these operations to support
   high-level summaries corresponding to the R functions =any=, =all=,
   =range=, =weighted.mean=, =IQR=, =mad=, etc.
   
   A prerequisite of aggregation is finding the distinct field
   combinations that correspond to each correspond to a group. Those
   combinations themselves constitute a useful summary, and we can
   retrieve them with =unique=:
   #+begin_src R
   unique(sr["tailnum"])
   unique(sr[c("origin", "tailnum")])
   #+end_src
   
   Solr also supports extracting the top or bottom N documents, after
   ranking by some field, optionally by group.

   The convenient, top-level function for aggregating data is
   =aggregate=. To compute a global aggregation,
   we just specify the computation as an expression (via a named
   argument, mimicking =transform=):
   #+begin_src R
   aggregate(sr, delay = mean(dep_delay, na.rm=TRUE))
   #+end_src
   It is also possible to specify a function (as the =FUN= argument),
   which would be passed the entire frame.

   As with =stats::aggregate=, we can pass a grouping as a formula:
   #+begin_src R
     delay <- aggregate(~ tailnum, sr,
                        count = TRUE,
                        dist = mean(distance, na.rm=TRUE),
                        delay = mean(arr_delay, na.rm=TRUE))
     delay <- subset(delay, count > 20 & dist < 2000)
   #+end_src
   The special =count= argument is a convenience for the common case
   of computing the number of documents in each group.

   Here is an example of using =nunique= and =ndoc=:
   #+begin_src R
     head(aggregate(~ dest, sr,
                    nplanes = nunique(tailnum),
                    nflights = ndoc(tailnum)))
   #+end_src
